{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kKN8kMKvTxL4",
        "C2eZwL_85n27"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/entc-17-fyp-20/CM_Normal_Behaviour_Modeling/blob/akeshala/CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yYYR26TblHY",
        "outputId": "634542c4-c557-4048-a5cd-50c26daf6f8c"
      },
      "source": [
        "# Run this cell when notebook is run from a different google account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_sWNneMfHmN"
      },
      "source": [
        "# Import libraries and datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98Me_SNS30m"
      },
      "source": [
        "# multivariate data preparation\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from datetime import datetime\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, BatchNormalization, Dropout, LocallyConnected2D, LeakyReLU, ReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0wOkP6TWPO2"
      },
      "source": [
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-00gDgoXe3j4"
      },
      "source": [
        "#@title Select Dataset New { display-mode: \"form\" }\n",
        "turbine = 'T01' #@param [\"T01\", \"T02\",\"T03\",\"T22\",\"T34\",\"T54\"]\n",
        "path = '/content/drive/MyDrive/IIoT - Wind Turbine/FYP/Dataset/Merged/' + turbine + '.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "809oqIDFKuQE"
      },
      "source": [
        "n_steps = 144"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPmqln5_w8p"
      },
      "source": [
        "#@title Select scaling method { display-mode: \"form\" }\n",
        "method = 'MinMax' #@param [\"Normalize\", \"MinMax\"]\n",
        "\n",
        "df_time = df[\"Date_Time\"]\n",
        "df.drop(\"Date_Time\", axis='columns', inplace=True)\n",
        "column_names = df.columns\n",
        "\n",
        "if method == \"Normalize\":\n",
        "  d = preprocessing.normalize(df, axis=0)\n",
        "else:\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  d = scaler.fit_transform(df)\n",
        "\n",
        "df = pd.DataFrame(d, columns=column_names)\n",
        "df[\"Date_Time\"] = df_time\n",
        "df = df.set_index(df['Date_Time'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf_OdQd6bclX"
      },
      "source": [
        "n_features = 4\n",
        "\n",
        "format = '%Y-%m-%d %H:%M:%S'\n",
        "split_index=[];\n",
        "split_index.append(df['Date_Time'][0])\n",
        "for i in range(0,len(df['Date_Time'])-1):\n",
        "  current_time =  df['Date_Time'][i]\n",
        "  following_time=  df['Date_Time'][i+1]\n",
        "  time_gap =datetime.strptime(following_time, format)-datetime.strptime(current_time, format)\n",
        "  if (time_gap.total_seconds() != 600):\n",
        "    split_index.append(current_time)\n",
        "    split_index.append(following_time)\n",
        "split_index.append(df['Date_Time'][len(df['Date_Time'])-1])\n",
        "\n",
        "df = df.set_index(df['Date_Time'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIrACxjc61WJ"
      },
      "source": [
        "# print(len(split_index))\n",
        "# print(len(split_index)*0.57)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7l3BAIT7ODj"
      },
      "source": [
        "# i = 128"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc7w74686t74"
      },
      "source": [
        "# df[split_index[i]:split_index[i+1]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T55MaZrZu_sU"
      },
      "source": [
        "X_concat_train, y_concat_train, y_concat_test, X_concat_test = [],[],[],[]\n",
        "\n",
        "for i in range(0,len(split_index),2):\n",
        "  dfx = df[split_index[i]:split_index[i+1]]\n",
        "  if len(dfx)>=144:\n",
        "    dfx = dfx[['Active_Power','Ambient_Temperature','Wind_Speed','Generator_RPM','Gear_Oil_Tempeature']]\n",
        "    dfx = dfx.to_numpy()\n",
        "    # convert into input/output\n",
        "    X, y = split_sequences(dfx, n_steps)\n",
        "    if i<len(split_index)*0.57:\n",
        "      X_concat_train.append(X)\n",
        "      y_concat_train.append(y)\n",
        "    elif i<=len(split_index)*1:\n",
        "      X_concat_test.append(X)\n",
        "      y_concat_test.append(y)\n",
        "\n",
        "X_concat_train = tuple(X_concat_train)\n",
        "y_concat_train = tuple(y_concat_train)\n",
        "\n",
        "X_concat_test = tuple(X_concat_test)\n",
        "y_concat_test = tuple(y_concat_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaNBi5BxhnCM"
      },
      "source": [
        "X_train = np.concatenate(X_concat_train)\n",
        "y_train = np.concatenate(y_concat_train)\n",
        "\n",
        "X_test = np.concatenate(X_concat_test)\n",
        "y_test = np.concatenate(y_concat_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n_vI1egX5pP",
        "outputId": "03ae9cc6-1927-4fbf-8980-ca1390abb5fc"
      },
      "source": [
        "print(\"Train \"+str(len(X_train)))\n",
        "print(\"Test \"+str(len(X_test)))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 40517\n",
            "Test 28741\n",
            "(40517, 144, 4)\n",
            "(40517,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doq5i4tVDED4"
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],X_test.shape[2],1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKN8kMKvTxL4"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip56e10mTvkP"
      },
      "source": [
        "def create_model():\n",
        "# define model\n",
        "  model1 = Sequential()\n",
        "  model1.add(Conv2D(filters=128, kernel_size=(32,4), padding=\"same\", input_shape=(n_steps, n_features,1)))\n",
        "  model1.add(BatchNormalization())\n",
        "  # model1.add(ReLU())\n",
        "  model1.add(Dropout(0.1))\n",
        "  model1.add(Conv2D(filters=128, kernel_size=(18,4), padding=\"same\"))\n",
        "  model1.add(BatchNormalization())\n",
        "  # model1.add(ReLU())\n",
        "  model1.add(Dropout(0.1))\n",
        "  model1.add(Conv2D(filters=128, kernel_size=(8,4), padding=\"same\"))\n",
        "  model1.add(BatchNormalization())\n",
        "  # model1.add(ReLU())\n",
        "  model1.add(Dropout(0.1))\n",
        "  model1.add(Conv2D(filters=128, kernel_size=(8,4), padding=\"same\"))\n",
        "  model1.add(BatchNormalization())\n",
        "  # model1.add(ReLU())\n",
        "  model1.add(Dropout(0.1))\n",
        "  model1.add(LocallyConnected2D(filters=10, kernel_size=(8, 4), activation=\"relu\"))\n",
        "  model1.add(Flatten())\n",
        "  model1.add(Dense(20, activation='relu'))\n",
        "  model1.add(Dense(1))\n",
        "  model1.add(LeakyReLU(alpha=0.1))\n",
        "  model1.compile(optimizer='adam', loss='mse')\n",
        "  return model1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2eZwL_85n27"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkOGei-DYIEX",
        "outputId": "65052b56-f78e-4f2b-fee2-10792f78b5d6"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3)\n",
        "\n",
        "best_val = ModelCheckpoint('model_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rktALRXfYL8s",
        "outputId": "01f4e031-2dff-417a-c95c-87aa21134651"
      },
      "source": [
        "n_features = X_train.shape[2]\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, batch_size=5, validation_data=(X_test,y_test), callbacks=[earlystop, best_val], epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8104/8104 [==============================] - 520s 60ms/step - loss: 0.0267 - val_loss: 0.0045\n",
            "Epoch 2/10\n",
            "8104/8104 [==============================] - 496s 61ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 3/10\n",
            "8104/8104 [==============================] - 481s 59ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "Epoch 4/10\n",
            "7515/8104 [==========================>...] - ETA: 29s - loss: 0.0019"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFRySm2JYUEB"
      },
      "source": [
        "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
        "model.load_weights(\"model_{:02d}.h5\".format(best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8RDxA_wYYgT"
      },
      "source": [
        "plot_df = pd.DataFrame.from_dict({'train_loss':history.history['loss'], 'val_loss':history.history['val_loss']})\n",
        "plot_df.plot(logy=True, figsize=(10,10), fontsize=12)\n",
        "plt.xlabel('epoch', fontsize=12)\n",
        "plt.ylabel('loss', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbr6GkxuNGqY"
      },
      "source": [
        "# Save the weights\n",
        "path = '/content/drive/MyDrive/Machine Learning Models/FYP/CNN2.2/'\n",
        "model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrwN8ud2_-sw"
      },
      "source": [
        "# Import pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKAd2tzZADe6"
      },
      "source": [
        "path = '/content/drive/MyDrive/Machine Learning Models/FYP/CNN2.2/'\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "# Restore the weights\n",
        "model.load_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwDNypNW5sVI"
      },
      "source": [
        "# Testing on the same turbine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAtkro2u5ucu"
      },
      "source": [
        "# demonstrate prediction\n",
        "yhat = model.predict(X_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxI8-XK-ALeQ"
      },
      "source": [
        "yhat = yhat.reshape(yhat.shape[0],)\n",
        "df_final=pd.DataFrame({'y_hat':yhat,'y_test':y_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0BpM-Kk-2CK"
      },
      "source": [
        "df_final['difference'] = df_final['y_hat']-df_final['y_test']\n",
        "df_final[\"abs_difference\"] = abs(df_final['y_hat']-df_final['y_test'])\n",
        "print(df_final[\"difference\"].mean())\n",
        "print(df_final[\"abs_difference\"].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtFRMTwahxAU"
      },
      "source": [
        "# df_final.to_csv('drive/MyDrive/DatasetsWind/df_final.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNqWRpExBZhn"
      },
      "source": [
        "# Results, Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXt2kKQNQT8R"
      },
      "source": [
        "# Adding data_time column back\n",
        "frames = []\n",
        "\n",
        "for i in range(0,len(split_index),2):\n",
        "  dfx = df[split_index[i]:split_index[i+1]]\n",
        "\n",
        "  if i>=len(split_index)*0.57:\n",
        "    frames.append(dfx.iloc[n_steps-1:,:])\n",
        "\n",
        "test = pd.concat(frames)\n",
        "test.drop(\"Date_Time\", axis='columns', inplace=True)\n",
        "test = test.reset_index()\n",
        "df_final[\"Date_Time\"] = test[\"Date_Time\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mrggrViXak"
      },
      "source": [
        "column_name = 'y_test' \n",
        "column_name1 = 'y_hat'\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df_final['Date_Time'], y=df_final[column_name], mode='lines', name='Actual'))\n",
        "fig.add_trace(go.Scatter(x=df_final['Date_Time'],y=df_final[column_name1], mode='lines', name='Predicted'))\n",
        "fig.update_layout(title_text= \"Actual vs Predicted\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcqoHSV1LyFH"
      },
      "source": [
        "column_name = 'difference' \n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df_final['Date_Time'], y=df_final[column_name], mode='lines', name='Error'))\n",
        "fig.update_layout(title_text= \"Error\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2OXhJ6gX_Ax"
      },
      "source": [
        "column_name = 'abs_difference' \n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df_final['Date_Time'], y=df_final[column_name], mode='lines', name='Absolute Error'))\n",
        "fig.update_layout(title_text= \"Absolute Error\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIrVFpczbk7Z"
      },
      "source": [
        "Re-sampling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFGOZk1dSnm"
      },
      "source": [
        "#@title Resampling { display-mode: \"form\" }\n",
        "sample_frequency = 60 #@param {type:\"slider\", min:20, max:120, step:10}\n",
        "sample = str(sample_frequency) + \"min\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bVGeP26ZdDL"
      },
      "source": [
        "df_final['Date_Time'] = pd.to_datetime(df_final['Date_Time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "df_final.set_index('Date_Time', inplace = True)\n",
        "df_resample = df_final.resample(sample).mean().reset_index()\n",
        "df_final = df_final.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCYuE0pr7YI_"
      },
      "source": [
        "df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6SNA4_oadsl"
      },
      "source": [
        "column_name = 'difference' \n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df_resample['Date_Time'], y=df_resample[column_name], mode='lines', name='Error'))\n",
        "fig.update_layout(title_text= \"Error\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q95eoihxaze3"
      },
      "source": [
        "column_name = 'abs_difference' \n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df_resample['Date_Time'], y=df_resample[column_name], mode='lines', name='Absolute Error'))\n",
        "fig.update_layout(title_text= \"Absolute Error\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOEUo8j-PqiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}